---
layout: post
title: AI Factories 2025H2
hidden: true
date: 2025-11-06 08:00:00 +0200
categories: [top20,data,ai]
tags: [nvidia,datacenter]
---

# ðŸŒ AI Factories Top 20 â€” 2025 H2 Edition

*Inspired by the [TOP500 Supercomputer List](https://www.top500.org), this list ranks the largest known or announced AI training infrastructures worldwide â€” often called â€œAI Factoriesâ€.  
Figures are based on public announcements, credible leaks, and infrastructure analysis as of November 2025.*

---

| ðŸ… Rank | Name / Project | ðŸŒ Location | ðŸ¢ Owner / Operator | âš™ï¸ GPU Count / Compute Scale | ðŸ§© Platform / Architecture | ðŸ“† Status | ðŸ“ Notes |
|:--:|:------------------|:-------------|:--------------------|:-----------------------------|:--------------------------|:-----------|:---------|
| **1** | **Stargate (OpenAI + Microsoft)** | Quincy, WA, USA | Microsoft / OpenAI | ~150,000+ NVIDIA Blackwell GPUs *(planned)* | Azure AI Fabric | Announced (2024) | Part of $100B multi-phase AI infrastructure expansion |
| **2** | **Frontier AI Factory (NVIDIA + CoreWeave)** | USA | CoreWeave / NVIDIA | ~100,000 GPUs *(H100/B100 mix)* | DGX Cloud | Under Construction | NVIDIAâ€™s flagship partner cloud cluster |
| **3** | **xAI â€œColossusâ€ Cluster (Elon Musk / xAI)** | USA | xAI | ~100,000 GPUs *(H100 + B200)* | Custom Tesla Dojo hybrid | Building (2025) | Colossus 1 & 2; dedicated to Grok model suite |
| **4** | **Amazon Bedrock / Titan Cluster** | USA | AWS | ~80,000 GPUs equivalent | Trainium + H100 mix | Operational | Internal Amazon FMs training platform |
| **5** | **Google Gemini Training Infrastructure** | USA | Google DeepMind | ~70,000 GPUs *(A3 Mega + TPUv5e)* | TPUv5e / TPUv6 | Operational | Powers Gemini and multimodal DeepMind systems |
| **6** | **Meta â€œAI Research SuperClusterâ€ (RSC 2)** | USA | Meta | ~60,000 GPUs *(H100/B200)* | PyTorch / NVIDIA DGX | Under Expansion | Successor to RSC Phase 1 (16k A100s) |
| **7** | **Azure â€œAI Supercomputerâ€ Cluster** | USA + EU | Microsoft Azure | ~60,000+ GPUs *(H100s)* | Azure NDv5 | Operational | Used for OpenAI + Copilot workloads |
| **8** | **G42 Condor Galaxy (UAE)** | Abu Dhabi, UAE | G42 + Cerebras | ~54,000 GPU-equivalents | Cerebras WSE + NVIDIA | Expansion (CG-2, CG-3) | Key MENA AI hub, multi-region rollout |
| **9** | **China â€œBaidu AI Cloudâ€ Cluster** | Beijing, China | Baidu | ~50,000 GPUs *(H800 / Ascend 910B)* | Kunlun + NVIDIA H800 | Operational | Baiduâ€™s core generative AI infrastructure |
| **10** | **Alibaba Tongyi Cluster** | Hangzhou, China | Alibaba Cloud | ~45,000 GPUs *(H800 / Ascend 910B)* | PAI / Lingjun AI Infra | Operational | Powers Tongyi Qianwen LLM family |
| **11** | **Tencent AI SuperCenter** | Shenzhen, China | Tencent | ~40,000 GPUs | H800 + Blackwell *(planned)* | Expansion | Supports Hunyuan model suite |
| **12** | **DOE â€œFrontier AI Discoveryâ€ Project** | Oak Ridge, USA | U.S. Dept. of Energy (DOE) | ~35,000 GPUs equivalent | AMD Instinct / HPE Cray | Building (2025) | Research-oriented, exascale AI-HPC hybrid |
| **13** | **DOE â€œLuxâ€ AI Facility** | USA | U.S. Dept. of Energy | ~30,000 GPUs equivalent | Hybrid DOE HPC / NVIDIA | Announced | Next-gen AI scientific computing center |
| **14** | **EU â€œJUPITER AI Extensionâ€ (EuroHPC)** | JÃ¼lich, Germany | EuroHPC / Forschungszentrum JÃ¼lich | ~25,000 GPUs *(MI300A + H100)* | Modular Supercomputing | Under Construction- | Europeâ€™s flagship AI-HPC hybrid |
| **15** | **Saudi NEOM AI Factory** | NEOM, Saudi Arabia | NEOM Tech / NVIDIA | ~24,000 GPUs | NVIDIA + Oracle Cloud | Announced | AI hub for NEOM smart city projects |
| **16** | **ETH Zurich â€œAlpsâ€ AI-HPC** | Zurich, Switzerland | CSCS / ETH | ~22,000 GPUs | NVIDIA Grace Hopper | Launching 2025 | European sovereign AI compute center |
| **17** | **France â€œJean Zay 2â€ AI Upgrade** | Paris, France | GENCI | ~20,000 GPUs | NVIDIA / Atos BullSequana | Construction | French national AI infrastructure |
| **18** | **Japan â€œABCI 3.0â€** | Tokyo, Japan | AIST | ~18,000 GPUs | NVIDIA H200 | Planned (2025) | Asiaâ€™s open AI research cluster |
| **19** | **Amazon / Anthropic â€œClaude Factoryâ€** | USA | AWS + Anthropic | ~15,000 GPUs | Trainium2 / H100 | Operational | Dedicated to Claude 3+ and next-gen models |
| **20** | **OpenAI â€œLegacy Azure Clusterâ€ (SuperPod)** | Iowa, USA | Microsoft / OpenAI | ~14,000 GPUs *(A100s)* | Azure AI | Operational | Former GPT-4 / GPT-3 training supercluster |

---

> **Notes (2025):**
{: .prompt-info }

> - ðŸ­ â€œAI Factoriesâ€ are large-scale GPU or accelerator clusters dedicated to training or serving AI foundation models.

> - ðŸ§  GPU counts are based on credible estimates; real totals may vary due to hybrid architectures (TPUs, WSEs, Trainium, etc.).

> - ðŸŒŽ The U.S. leads in installed capacity, but **UAE**, **China**, and **EU** projects are rapidly expanding.  
> - ðŸš€ Projects like **Stargate** and **Frontier AI Factory** mark the beginning of the *100k+ GPU era* of AI infrastructure.  
> - âš¡ Expect several >200k-GPU builds to break ground before 2026.

---


_Last updated: November 2025_  
_Source: company filings, press releases, HPC community trackers, and infrastructure research._
